<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>ARLearn</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheet/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheet/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheet/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">ARLearn</h1>
      <h2 class="project-tagline">Learning has never been more fun: A markerless AR based tutor for kids using deep learning</h2>
<!--       <a href="https://youtu.be/3LYjsKIqUAE" class="btn">Demo Video</a> -->
     
    </section>

    <section class="main-content">
      <h3>
<a id="welcome-to-arlearn" class="anchor" href="#welcome-to-arlearn" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome to ARLearn</h3>

<p>Animation and Graphics are extensively used to organise information, to foster insight, to facilitate memory and inference. To this end, we present an interactive and immersive augmented reality tutor for kids to learn alphabets and numbers on a hand-held device. 3D animations serve as a reward for construction of alphabets correctly.This engages children grabbing their attention and maintaining motivation during the learning process. The application is tested on subjects between ages 2 to 6 who were instructed to make models of alphabets/numbers with clay. The AR application starts by prompting the child with the alphabet shape to construct. Once the child constructs an alphabet using a clay model on a plain surface such as the table top, an image is captured by the application and sent to the recognition engine. Since children can create alphabets that could be slightly deformed - the proposed method utilises spatial transformer networks (STNs) with CNNs that work on alphabet recognition. It is robust and invariant to scaling, rotation, and affine transformations amongst others. The novelty is two fold in comparison with the state-of-the-art (a) by being generic in the sense that even though the demo video utilises clay models, it can be generalised to other alphabet learning methods: slate and a chalk, white paper and a color pencil/pen, white board and pen to name a few (b) by alleviating the need of explicit markers such as the flash cards to overlay the animation.</p>

<h3>
<a id="the-idea" class="anchor" href="#the-idea" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Idea</h3>

<p><img src="https://github.com/rhebbalaguppe/ARLearn/blob/master/img/proposed-method.png?raw=true?" alt="Proposed Method "></p>


<h3>
<a id="the-idea" class="anchor" href="#the-idea" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Demo Video</h3>
  <iframe width="560" height="315" src="https://github.com/rhebbalaguppe/ARLearn/blob/master/img/demo.mp4" frameborder="0" allowfullscreen></iframe>
      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/rhebbalaguppe/ARLearn">ARLearn</a> is maintained by <a href="https://github.com/rhebbalaguppe">rhebbalaguppe</a>.</span>

      </footer>

    </section>

  
  </body>
</html>
